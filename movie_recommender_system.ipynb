{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Movie Recommendation System: Item-Based Collaborative Filtering**\n",
    "\n",
    "---\n",
    "\n",
    "## **Project Objective**\n",
    "\n",
    "In this project, we will build an **item-based collaborative filtering recommender system** using the **Surprise library**. The system will allow users to:\n",
    "\n",
    "1. Receive movie recommendations based on a specific movie title (e.g., \"The Lion King\").\n",
    "2. Understand how item-based collaborative filtering works.\n",
    "3. Compute item-item similarity scores to recommend movies that are similar in terms of user preferences.\n",
    "\n",
    "We will:\n",
    "- Use a real-world movie dataset.\n",
    "- Preprocess the dataset.\n",
    "- Train a recommendation model using **KNN-based algorithms**.\n",
    "- Query the system for recommendations based on movie titles.\n",
    "\n",
    "The project includes detailed explanations of each step and insights into the underlying concepts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Prerequisites**\n",
    "\n",
    "### **Libraries Needed**\n",
    "\n",
    "Install the required libraries before starting the project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Surprise**: A library designed specifically for building recommender systems.\n",
    "- **Pandas**: For data manipulation and preprocessing.\n",
    "- **Numpy**: For numerical computations.\n",
    "- **Matplotlib & Seaborn**: For data visualization.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Dataset Overview**\n",
    "\n",
    "### **Dataset Requirements**\n",
    "For this project, we will use a movie dataset with the following columns:\n",
    "\n",
    "1. `userId`: A unique ID representing each user.\n",
    "2. `movieId`: A unique ID representing each movie.\n",
    "3. `rating`: The numeric rating (e.g., 1-5 or 1-10) given by a user to a movie.\n",
    "4. `title`: The name of the movie (used for querying recommendations).\n",
    "\n",
    "### **Loading the Dataset**\n",
    "We will use the **MovieLens dataset** (small version), which contains user ratings for movies along with metadata such as movie titles. You can download it from [MovieLens](https://grouplens.org/datasets/movielens/).\n",
    "\n",
    "Save the dataset locally and load it into your project.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Loading and Preparing the Dataset**\n",
    "\n",
    "### **Step 1: Load the Ratings Data**\n",
    "\n",
    "We first load the dataset containing `userId`, `movieId`, and `rating` columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rating.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the ratings data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ratings_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrating.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your ratings file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m ratings_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(ratings_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rating.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ratings data\n",
    "ratings_path = \"rating.csv\"  # Replace with the path to your ratings file\n",
    "ratings_df = pd.read_csv(ratings_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(ratings_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.drop(columns=['timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating\n",
      "0       1        2     3.5\n",
      "1       1       29     3.5\n",
      "2       1       32     3.5\n",
      "3       1       47     3.5\n",
      "4       1       50     3.5\n"
     ]
    }
   ],
   "source": [
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Explanation:**\n",
    "- `pd.read_csv()` loads the dataset into a pandas DataFrame.\n",
    "- Ensure the dataset contains `userId`, `movieId`, and `rating` columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Step 2: Load the Movie Metadata**\n",
    "\n",
    "Next, we load the metadata containing `movieId` and `title`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the movies data\n",
    "movies_path = \"movie.csv\"  # Replace with the path to your movies file\n",
    "movies_df = pd.read_csv(movies_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "movies_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Step 3: Merge Datasets**\n",
    "\n",
    "We merge the `ratings_df` with `movies_df` to include movie titles in the ratings dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Merge ratings with movie titles\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ratings_with_titles \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mratings_df\u001b[49m, movies_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the merged dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m ratings_with_titles\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ratings_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge ratings with movie titles\n",
    "ratings_with_titles = pd.merge(ratings_df, movies_df, on=\"movieId\")\n",
    "\n",
    "# Display the first few rows of the merged dataset\n",
    "ratings_with_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings_with_titles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mratings_with_titles\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ratings_with_titles' is not defined"
     ]
    }
   ],
   "source": [
    "ratings_with_titles[\"rating\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_with_titles[\"rating\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Preparing the Data for Surprise**\n",
    "\n",
    "In this step, we need to prepare the movie ratings data to work with the Surprise library. One of the key things the Surprise library needs is the **rating scale** — this simply tells the system what the minimum and maximum possible ratings are in our dataset.\n",
    "\n",
    "In the dataset, the ratings given by users can range from 0.5 to 5.0 (this is common for movie ratings). **Surprise** needs to know this so it can understand how to process the data correctly.\n",
    "\n",
    "- **Surprise** needs to know these values to properly interpret the ratings in our dataset and to calculate accurate predictions for movie recommendations.\n",
    "\n",
    "We use **Surprise's `Reader` class** to define this rating scale, and then we convert our pandas DataFrame into a Surprise dataset.\n",
    "\n",
    "`Dataset.load_from_df()` converts the pandas DataFrame into a Surprise-compatible dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "\n",
    "# Define the rating scale (e.g., 0.5 to 5.0)\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# Convert the DataFrame to a Surprise dataset\n",
    "data = Dataset.load_from_df(ratings_with_titles[[\"userId\", \"movieId\", \"rating\"]], reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **4. Split the Data**\n",
    "\n",
    "In this step, we will **split** the dataset into two parts:\n",
    "- **Training Set**: 80% of the data will be used to train the recommendation model.\n",
    "- **Testing Set**: 20% of the data will be used to evaluate the model's performance.\n",
    "\n",
    "#### **Why do we split the data?**\n",
    "\n",
    "- **Training**: The training set helps the model learn patterns and relationships between users and movies.\n",
    "- **Testing**: The testing set is used to check how well the model performs when making predictions on new, unseen data. It helps us evaluate the accuracy of the recommendations.\n",
    "\n",
    "We use **Surprise's `train_test_split()` function** to split the dataset. Here's how we can do that:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Explanation:**\n",
    "- `train_test_split()` splits the dataset into training and testing sets.\n",
    "- `test_size=0.2` allocates 20% of the data for testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Building the Item-Based Collaborative Filtering Model**\n",
    "\n",
    "In this step, we will build the recommendation model using **item-based collaborative filtering**. This approach recommends items (movies) based on the similarities between them.\n",
    "\n",
    "We will use **KNNBasic**, a popular algorithm from the Surprise library, to compute similarities between items (movies).\n",
    "\n",
    "### **Step 1: Configure the Model**\n",
    "\n",
    "We need to configure the model by specifying the **similarity metric** (how items will be compared) and choosing whether the filtering is **user-based** or **item-based**.\n",
    "\n",
    "#### **Why Item-Based Collaborative Filtering?**\n",
    "\n",
    "- In item-based collaborative filtering, the system recommends items that are similar to the ones the user has already liked. For example, if you liked \"The Lion King,\" the system will recommend movies that other users who liked \"The Lion King\" also enjoyed.\n",
    "- **KNNBasic** will compute similarity scores between movies based on how often they are rated similarly by users.\n",
    "\n",
    "We’ll configure the model by choosing a similarity measure (e.g., **cosine similarity**) and setting **user_based=False** to ensure that we are using **item-based** filtering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x2b23a8e6050>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "# Define similarity options\n",
    "sim_options = {\n",
    "    'name': 'cosine',  # Use cosine similarity to measure the similarity between items\n",
    "    'user_based': False  # Set to False for item-based filtering (True would be for user-based filtering)\n",
    "}\n",
    "\n",
    "# Build the model using the KNNBasic algorithm\n",
    "item_cf_model = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Train the model on the training set\n",
    "item_cf_model.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Explanation:**\n",
    "- `sim_options`: Specifies the similarity metric (`cosine`) and the type of filtering (`user_based=False` for item-based).\n",
    "- `KNNBasic`: Computes similarity scores and makes predictions.\n",
    "- `fit()`: Trains the model on the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Model Training Insights**\n",
    "\n",
    "During training, the model computes similarity scores between all pairs of items (movies). This is done by comparing how users rate these items. \n",
    "\n",
    "For example:\n",
    "- If many users rate **The Lion King** and **Aladdin** similarly, these movies will have a high similarity score.\n",
    "\n",
    "#### **What We Can Do:**\n",
    "\n",
    "We can print out the ratings for two movies (e.g., *The Lion King* and *Aladdin*) to see how users rate them, and use that information to understand why the system might compute a high similarity score between them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie 'The Lion King' not found.\n",
      "Movie: Aladdin, Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Define movie titles\n",
    "movie_title_1 = \"The Lion King\"\n",
    "movie_title_2 = \"Aladdin\"\n",
    "\n",
    "# Find the movie IDs for the given titles from the combined DataFrame\n",
    "movie_id_1 = ratings_with_titles[ratings_with_titles['title'].str.contains(movie_title_1, case=False, na=False)]['movieId'].values\n",
    "movie_id_2 = ratings_with_titles[ratings_with_titles['title'].str.contains(movie_title_2, case=False, na=False)]['movieId'].values\n",
    "\n",
    "# Check if the movie titles were found\n",
    "if len(movie_id_1) > 0:\n",
    "    rating_1 = ratings_with_titles[ratings_with_titles['movieId'] == movie_id_1[0]]['rating'].values[0]\n",
    "    print(f\"Movie: {movie_title_1}, Rating: {rating_1}\")\n",
    "else:\n",
    "    print(f\"Movie '{movie_title_1}' not found.\")\n",
    "\n",
    "if len(movie_id_2) > 0:\n",
    "    rating_2 = ratings_with_titles[ratings_with_titles['movieId'] == movie_id_2[0]]['rating'].values[0]\n",
    "    print(f\"Movie: {movie_title_2}, Rating: {rating_2}\")\n",
    "else:\n",
    "    print(f\"Movie '{movie_title_2}' not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Making Recommendations Based on a Movie Title**\n",
    "\n",
    "In this step, we will define a function that allows us to find movies similar to a given movie title. This will help users understand how item-based collaborative filtering works and how recommendations are generated.\n",
    "\n",
    "### **Function to Find Similar Movies**\n",
    "\n",
    "The function will take a **movie title** as input and return a list of the most similar movies based on user ratings. We will use the model trained earlier to find the **most similar items** to the one the user is interested in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies(movie_title, model, trainset, movies_df, top_n=5):\n",
    "    # Find the movie ID for the given title\n",
    "    movie_id = movies_df[movies_df['title'].str.contains(movie_title, case=False, na=False)]['movieId'].values\n",
    "\n",
    "    # Convert the movieId to an internal ID used by Surprise (trainset)\n",
    "    movie_inner_id = trainset.to_inner_iid(movie_id[0])\n",
    "\n",
    "    # Get the top N most similar movies using the KNN model's get_neighbors function\n",
    "    neighbors = model.get_neighbors(movie_inner_id, k=top_n)\n",
    "\n",
    "    # Map internal IDs back to movie titles\n",
    "    similar_titles = [(movies_df[movies_df['movieId'] == int(trainset.to_raw_iid(neighbor))]['title'].values[0])\n",
    "                      for neighbor in neighbors]\n",
    "\n",
    "    return similar_titles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Retrieving Recommendations Based on Movie Title**\n",
    "\n",
    "In the last section, we're calling the `get_similar_movies` function to retrieve recommendations for a given movie title (in this case, \"The Lion King\"). The process is as follows:\n",
    "\n",
    "### **1. Movie Title Input**:\n",
    "We provide the movie title \"The Lion King\" as an example input.\n",
    "\n",
    "### **2. Get Similar Movies**:\n",
    "We use the `get_similar_movies` function to fetch the top 5 similar movies to \"The Lion King\". This function takes in the movie title, the trained collaborative filtering model (`KNNBasic_model`), the training dataset (`trainset`), and the movie DataFrame (`movies_df`) that holds the movie titles and IDs.\n",
    "\n",
    "### **3. Print the Recommendations**:\n",
    "The recommendations are returned as a list of tuples, where each tuple consists of a movie title and its similarity score. If the function successfully returns a list, we print the movie titles along with their similarity scores. If the movie title is not found or there is any issue, the function will return an error message instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar movies to 'Shooter':\n",
      "Grand Budapest Hotel, The (2014)\n",
      "Wordplay (2006)\n",
      "Sahara (1943)\n",
      "Bend of the River (1952)\n",
      "Another Year (2010)\n"
     ]
    }
   ],
   "source": [
    "# Movie title input\n",
    "movie_title = \"Shooter\"\n",
    "\n",
    "# Get the top 5 similar movies\n",
    "recommended_movies = get_similar_movies(movie_title, item_cf_model, trainset, movies_df, top_n=5)\n",
    "\n",
    "# Print the recommended movies (only titles)\n",
    "if isinstance(recommended_movies, list):\n",
    "    print(f\"Top 5 similar movies to '{movie_title}':\")\n",
    "    for movie in recommended_movies:\n",
    "        print(movie)\n",
    "else:\n",
    "    print(recommended_movies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
